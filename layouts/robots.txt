robots.txt — generated by Hugo
# 环境：生产环境放行；非生产环境一律禁止抓取，避免预发布被收录
{{- $isProd := or hugo.IsProduction (eq site.Params.env "production") -}}
{{- if not $isProd -}}
# Non-production: block all
User-agent: *
Disallow: /
{{- else -}}
# Production rules
User-agent: *
Allow: /
Disallow:

# 仅示例：Google-Extended 可抓取 /posts/，并设置爬取间隔
User-agent: Google-Extended
Allow: /posts/
Crawl-delay: 10

# Googlebot 允许全站，排除 /private/
User-agent: Googlebot
Allow: /
Disallow: /private/

# Sitemap（绝对路径）
Sitemap: {{ "sitemap.xml" | absURL }}
{{- end -}}
